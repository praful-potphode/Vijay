{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "adfkharadi"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/ds_ss25_oracle')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_oracle_shantanu",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "OracleTable",
				"schema": [],
				"typeProperties": {
					"schema": "HR",
					"table": "TRANSACTIONS"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_transaction_anuja')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_oracle_anuja",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "OracleTable",
				"schema": [],
				"typeProperties": {
					"schema": "HR",
					"table": "TRANSACTIONS"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF_AC_SERIAL')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_AC_INPUT",
								"type": "DatasetReference"
							},
							"name": "INPUT"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "OUTPUT"
						}
					],
					"transformations": [
						{
							"name": "ID"
						},
						{
							"name": "CONVERTTOINT"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          first_name as string,",
						"          last_name as string,",
						"          email as string,",
						"          gender as string,",
						"          salary as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> INPUT",
						"INPUT keyGenerate(output(ID as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> ID",
						"ID cast(output(",
						"          salary as integer '000'",
						"     ),",
						"     errors: true) ~> CONVERTTOINT",
						"CONVERTTOINT select(mapColumn(",
						"          first_name,",
						"          last_name,",
						"          email,",
						"          id = ID,",
						"          gender,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          first_name as string,",
						"          last_name as string,",
						"          gender as string,",
						"          salary as decimal(19,4)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> OUTPUT"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF_Abhijit')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_Input_AK",
								"type": "DatasetReference"
							},
							"name": "DSInputFile"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DS_OutPut_AK_08Oct",
								"type": "DatasetReference"
							},
							"name": "DSUKBankOutPutFemale08Oct"
						},
						{
							"dataset": {
								"referenceName": "DSUKBankOutPutMale08Oct",
								"type": "DatasetReference"
							},
							"name": "DSUKBankOutPutMale08Oct"
						}
					],
					"transformations": [
						{
							"name": "SelectedCoulmns"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "FilterMale"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Customer ID} as string,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as string,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as string,",
						"          Balance as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> DSInputFile",
						"DSInputFile select(mapColumn(",
						"          CustomerID = {Customer ID},",
						"          Name,",
						"          Surname,",
						"          Gender,",
						"          Age,",
						"          Region,",
						"          JobClassification = {Job Classification}",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> SelectedCoulmns",
						"SelectedCoulmns derive({Sr.No} = random(1)) ~> derivedColumn1",
						"derivedColumn1 split(Gender=='Female',",
						"     disjoint: false) ~> FilterMale@(FilterFemale, FilterMale)",
						"FilterMale@FilterFemale sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> DSUKBankOutPutFemale08Oct",
						"FilterMale@FilterMale sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> DSUKBankOutPutMale08Oct"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DS_AC_IP')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_AC_INCREMENTAL",
								"type": "DatasetReference"
							},
							"name": "ACINPUT"
						},
						{
							"dataset": {
								"referenceName": "AC_TRANSACTION",
								"type": "DatasetReference"
							},
							"name": "ACOUTPUT"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AC_TRANSACTION",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "MapDrifted1",
							"description": "Creates an explicit mapping for each drifted column"
						},
						{
							"name": "select1"
						},
						{
							"name": "surrogateKey1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Transaction_Date as string,",
						"          Customer_ID as string,",
						"          Transaction_ID as string,",
						"          Amount as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ACINPUT",
						"source(output(",
						"          id as integer,",
						"          Transaction_Date as date,",
						"          Customer_ID as integer,",
						"          Transaction_ID as integer,",
						"          Amount as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'SELECT COUNT(*) AS #COUNT FROM AC_TRANSACTIONS',",
						"     format: 'query') ~> ACOUTPUT",
						"ACINPUT, select1 join(1==1,",
						"     joinType:'cross',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"ACOUTPUT derive({#COUNT} = toInteger(byName('#COUNT'))) ~> MapDrifted1",
						"MapDrifted1 select(mapColumn(",
						"          {#COUNT}",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"join1 keyGenerate(output(SRNO as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 derive(ID = SRNO+{#COUNT}) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          ID,",
						"          Transaction_Date,",
						"          Customer_ID,",
						"          Transaction_ID,",
						"          Amount",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"select2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          Transaction_Date as date,",
						"          Customer_ID as integer,",
						"          Transaction_ID as integer,",
						"          Amount as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/copy1azuresql')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_anujadatasetcsv",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable2",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1",
							"description": "SrNo"
						},
						{
							"name": "cast1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          first_name as string,",
						"          last_name as string,",
						"          email as string,",
						"          gender as string,",
						"          salary as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 keyGenerate(output(Id as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 cast(output(",
						"          salary as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 select(mapColumn(",
						"          id = Id,",
						"          first_name,",
						"          last_name,",
						"          email,",
						"          gender,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          first_name as string,",
						"          last_name as string,",
						"          gender as string,",
						"          salary as decimal(19,4)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/copy2azuresql')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_ss25_copy2azureSQL",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_ss25AzureSQL",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1",
							"description": "SrNo"
						},
						{
							"name": "convertSalary2decimal"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          first_name as string,",
						"          last_name as string,",
						"          email as string,",
						"          gender as string,",
						"          salary as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 keyGenerate(output(Id as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 cast(output(",
						"          salary as integer",
						"     ),",
						"     errors: true) ~> convertSalary2decimal",
						"convertSalary2decimal select(mapColumn(",
						"          id = Id,",
						"          first_name,",
						"          last_name,",
						"          email,",
						"          gender,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          first_name as string,",
						"          last_name as string,",
						"          gender as string,",
						"          salary as decimal(19,4)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_p6ukbankcustomers",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Parquet1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Customer ID} as integer,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as string,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as date 'dd.MMM.yy',",
						"          Balance as double",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          Customer_ID = {Customer ID},",
						"          Name,",
						"          Surname,",
						"          Gender,",
						"          Age,",
						"          Region,",
						"          Job_Classification = {Job Classification},",
						"          Date_Joined = {Date Joined},",
						"          Balance",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'parquet',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_p6ukbankcustomers_df",
								"type": "DatasetReference"
							},
							"name": "p6ukbankcustomes"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_p6ukbankcustwithaudit",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						},
						{
							"name": "AuditCOlumns"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Customer ID} as string,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as string,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as string,",
						"          Balance as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> p6ukbankcustomes",
						"p6ukbankcustomes select(mapColumn(",
						"          CustomerID = {Customer ID},",
						"          Name,",
						"          Surname,",
						"          Gender,",
						"          Age,",
						"          Region,",
						"          JobClassification = {Job Classification},",
						"          DateJoined = {Date Joined},",
						"          Balance",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 derive(CreatedBy = 'Praful',",
						"          CreatedDate = currentDate()) ~> AuditCOlumns",
						"AuditCOlumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['p6uk.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow3')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_ss_8octCSV",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_ss8oct_json",
								"type": "DatasetReference"
							},
							"name": "Storeoutputss"
						},
						{
							"dataset": {
								"referenceName": "ds_json_femaledata",
								"type": "DatasetReference"
							},
							"name": "sinkFemaleData"
						}
					],
					"transformations": [
						{
							"name": "select1"
						},
						{
							"name": "filter1"
						},
						{
							"name": "sort1"
						},
						{
							"name": "split1"
						},
						{
							"name": "sort2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Customer ID} as string,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as string,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as string,",
						"          Balance as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          CustomerID = {Customer ID},",
						"          Name,",
						"          Surname,",
						"          Gender,",
						"          Age,",
						"          Region,",
						"          JobCategory = {Job Classification}",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"split1@SpiltbyMale filter(Region=='England') ~> filter1",
						"filter1 sort(asc(Name, false),",
						"     asc(CustomerID, true)) ~> sort1",
						"select1 split(Gender=='Male',",
						"     disjoint: false) ~> split1@(SpiltbyMale, SplitbyFemale)",
						"split1@SplitbyFemale sort(asc(CustomerID, false),",
						"     asc(Name, false)) ~> sort2",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> Storeoutputss",
						"sort2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['p6ukfemale.json'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sinkFemaleData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow4')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_p6ukbankcustomers",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "PSoutput",
								"type": "DatasetReference"
							},
							"name": "PSoutput"
						}
					],
					"transformations": [
						{
							"name": "PSTransform"
						},
						{
							"name": "filter1"
						},
						{
							"name": "sort1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Customer ID} as string,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as string,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as string,",
						"          Balance as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          {Customer account} = {Customer ID},",
						"          Name,",
						"          Surname,",
						"          Gender,",
						"          Age,",
						"          Region,",
						"          JobClassification = {Job Classification},",
						"          {Date.Joined} = {Date Joined},",
						"          Balance",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> PSTransform",
						"derivedColumn1 filter(Gender==\"Female\") ~> filter1",
						"filter1 sort(desc(Name, true),",
						"     desc(Age, true)) ~> sort1",
						"PSTransform derive(SrNo = random(1),",
						"          Agegroup = case(toInteger(Age)>22, 'Employed', 'UnEmployed')) ~> derivedColumn1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> PSoutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow5')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_DelimitedText_mock",
								"type": "DatasetReference"
							},
							"name": "input"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "maxid"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "employees",
								"type": "DatasetReference"
							},
							"name": "loaddatainazsql"
						}
					],
					"transformations": [
						{
							"name": "surrogateKeykey"
						},
						{
							"name": "arrangecolumns"
						},
						{
							"name": "convertsalarytodecimal"
						},
						{
							"name": "join1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select1"
						},
						{
							"name": "MapDrifted1",
							"description": "Creates an explicit mapping for each drifted column"
						},
						{
							"name": "select2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          first_name as string,",
						"          last_name as string,",
						"          email as string,",
						"          gender as string,",
						"          salary as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> input",
						"source(output(",
						"          id as integer,",
						"          first_name as string,",
						"          last_name as string,",
						"          gender as string,",
						"          salary as decimal(19,4)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select count(*) as  #count\\nfrom [dbo].[employees]',",
						"     format: 'query') ~> maxid",
						"select1 keyGenerate(output(index as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKeykey",
						"convertsalarytodecimal select(mapColumn(",
						"          id,",
						"          first_name,",
						"          last_name,",
						"          email,",
						"          gender,",
						"          salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> arrangecolumns",
						"derivedColumn1 cast(output(",
						"          salary as integer '000'",
						"     ),",
						"     errors: true) ~> convertsalarytodecimal",
						"input, select2 join(1==1,",
						"     joinType:'cross',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"surrogateKeykey derive(id = toInteger(index+rcount)) ~> derivedColumn1",
						"join1 select(mapColumn(",
						"          first_name,",
						"          last_name,",
						"          gender,",
						"          salary,",
						"          rcount = {#count},",
						"          email",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"maxid derive({#count} = toInteger(byName('#count'))) ~> MapDrifted1",
						"MapDrifted1 select(mapColumn(",
						"          {#count}",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"arrangecolumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          first_name as string,",
						"          last_name as string,",
						"          gender as string,",
						"          salary as decimal(19,4)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> loaddatainazsql"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow6')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_Transaction1_Data",
								"type": "DatasetReference"
							},
							"name": "Transaction1"
						},
						{
							"dataset": {
								"referenceName": "Transaction_Abhijit",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Transaction_Abhijit",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "MapDrifted1",
							"description": "Creates an explicit mapping for each drifted column"
						},
						{
							"name": "select1"
						},
						{
							"name": "join1"
						},
						{
							"name": "surrogateKey1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Transaction_Date as date,",
						"          Customer_ID as long '000,000,000',",
						"          Transaction_ID as integer,",
						"          Amount as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Transaction1",
						"source(output(",
						"          id as integer,",
						"          Transaction_Date as date,",
						"          Customer_ID as integer,",
						"          Transaction_ID as integer,",
						"          Amount as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select count (*) as #Count from dbo.Transactions_Abhijit',",
						"     format: 'query') ~> source1",
						"source1 derive({#Count} = toInteger(byName('#Count'))) ~> MapDrifted1",
						"MapDrifted1 select(mapColumn(",
						"          {#Count}",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"Transaction1, select1 join(1==1,",
						"     joinType:'cross',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 keyGenerate(output({Sr.No} as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 derive(id = {Sr.No}+{#Count}) ~> derivedColumn1",
						"derivedColumn1 select(skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"select2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          Transaction_Date as date,",
						"          Customer_ID as integer,",
						"          Transaction_ID as integer,",
						"          Amount as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_alterrow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_p6ukbankcustomers_df",
								"type": "DatasetReference"
							},
							"name": "customers"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_customers",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						},
						{
							"name": "cast1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Customer ID} as string,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as string,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as string,",
						"          Balance as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> customers",
						"customers alterRow(insertIf(toInteger(Age)>40)) ~> alterRow1",
						"alterRow1 cast(output(",
						"          {Customer ID} as integer,",
						"          {Date Joined} as date 'dd.MMM.yy'",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          {Customer ID} as integer,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as integer,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as date,",
						"          Balance as decimal(19,4)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['Customer ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_flatten_json')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_json_emp",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_csv_json_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          users as (userId as integer, firstName as string, lastName as string, phoneNumber as string, emailAddress as string)[]",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source1",
						"source1 foldDown(unroll(users),",
						"     mapColumn(",
						"          userid = users.userId,",
						"          firstName = users.firstName,",
						"          lastName = users.lastName,",
						"          phoneNumber = users.phoneNumber,",
						"          emailAddress = users.emailAddress",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_incremntal_load')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_az_transactions_05nov",
								"type": "DatasetReference"
							},
							"name": "source2"
						},
						{
							"dataset": {
								"referenceName": "ds_05nov2023",
								"type": "DatasetReference"
							},
							"name": "source3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_az_transactions_05nov",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "MapDrifted1",
							"description": "Creates an explicit mapping for each drifted column"
						},
						{
							"name": "select1"
						},
						{
							"name": "join1"
						},
						{
							"name": "surrogateKey1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          Transaction_Date as date,",
						"          Customer_ID as integer,",
						"          Transaction_ID as integer,",
						"          Amount as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select count(*) as #count from dbo.transactions',",
						"     format: 'query') ~> source2",
						"source(output(",
						"          Transaction_Date as string,",
						"          Customer_ID as string,",
						"          Transaction_ID as string,",
						"          Amount as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> source3",
						"source2 derive({#count} = toInteger(byName('#count'))) ~> MapDrifted1",
						"MapDrifted1 select(mapColumn(",
						"          {#count}",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"source3, select1 join(1==1,",
						"     joinType:'cross',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 keyGenerate(output(sno as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 derive(id = toInteger(sno+{#count}),",
						"          CustomerID = toInteger(Customer_ID)) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          id,",
						"          Transaction_Date,",
						"          Customer_ID = CustomerID,",
						"          Transaction_ID,",
						"          Amount",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"select2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          Transaction_Date as date,",
						"          Customer_ID as integer,",
						"          Transaction_ID as integer,",
						"          Amount as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_joins_empdept')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_emp",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "ds_dept",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_emp_dept",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "select1"
						},
						{
							"name": "derivedColumn2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          DEPARTMENT_ID as string,",
						"          MANAGER_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 join(source1@DEPARTMENT_ID == source2@DEPARTMENT_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> join1",
						"derivedColumn2 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          DEPARTMENT_NAME,",
						"          COMMISSION_PCT = Commission",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"join1 derive(Commission = iifNull(toDecimal(COMMISSION_PCT,3),0,toDecimal(COMMISSION_PCT,3))) ~> derivedColumn2",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[(concat('emp_dept',concat(toString(currentUTC(),'yyyyMMddhhmmss'),'.csv')))],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_rename_columns')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_renamecolumns",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_ukbankmodified",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Customer ID} as string,",
						"          Name as string,",
						"          Surname as string,",
						"          Gender as string,",
						"          Age as string,",
						"          Region as string,",
						"          {Job Classification} as string,",
						"          {Date Joined} as string,",
						"          Balance as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          Customer_ID = {Customer ID},",
						"          Name,",
						"          Surname,",
						"          Gender,",
						"          Age,",
						"          Region,",
						"          Job_Classification = {Job Classification},",
						"          Balance",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 derive(CreatedBy = 'Praful') ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['p6ukbank.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_scd_type2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_productsdim",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "ds_az_dimproducts",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_az_dimproducts",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "lookup1"
						},
						{
							"name": "cast1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          productid as string,",
						"          productname as string,",
						"          price as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          id as integer,",
						"          productid as integer,",
						"          productname as string,",
						"          price as decimal(19,4),",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer,",
						"          createdtime as date,",
						"          modifiedtime as date",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source2",
						"select1 derive(startdate = currentDate(),",
						"          iscurrent = 1,",
						"          createdtime = currentTimestamp()) ~> derivedColumn1",
						"cast1, source2 lookup(cast1@productid == source2@productid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"source1 cast(output(",
						"          productid as integer",
						"     ),",
						"     errors: true) ~> cast1",
						"lookup1 select(mapColumn(",
						"          productid = cast1@productid,",
						"          productname = source1@productname,",
						"          price = source1@price,",
						"          iscurrent",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          productid as integer,",
						"          productname as string,",
						"          price as decimal(19,4),",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer,",
						"          createdtime as date,",
						"          modifiedtime as date",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/powerquery1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ds_p6ukbankcustomers",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> ds_p6ukbankcustomers",
							"dataset": {
								"referenceName": "ds_p6ukbankcustomers",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared ds_p6ukbankcustomers = let AdfDoc = AzureStorage.BlobContents(\"https://storageaccountadfkharadi.blob.core.windows.net/adfcontainer/input/dataflow/P6-UK-Bank-Customers.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"ds_p6ukbankcustomers\" in Source;\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		}
	]
}